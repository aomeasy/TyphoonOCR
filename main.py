import streamlit as st
import requests
import base64
import json
from io import BytesIO
from PIL import Image
import PyPDF2
import tempfile
import os
import sys
import subprocess
from typing import Optional, Dict, Any, List, Tuple
import traceback
import hashlib
import pickle
import sqlite3
from datetime import datetime
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import markdown
import re

# Try importing pdf2image with error handling
try:
    import pdf2image
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False
    st.warning("‚ö†Ô∏è pdf2image not available. PDF conversion will use fallback method.")

# Page configuration
st.set_page_config(
    page_title="üå™Ô∏è Typhoon OCR with RAG",
    page_icon="üå™Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        text-align: center;
        color: white;
        margin-bottom: 2rem;
    }
    
    .feature-card {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
    }
    
    .model-card {
        background: linear-gradient(45deg, #e3f2fd, #bbdefb);
        padding: 1rem;
        border-radius: 10px;
        border: 2px solid #2196f3;
        text-align: center;
        margin: 0.5rem;
    }
    
    .success-message {
        background: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
    }
    
    .error-message {
        background: #f8d7da;
        color: #721c24;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #f5c6cb;
    }
    
    .warning-message {
        background: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    
    .user-message {
        background: #e3f2fd;
        border-left: 4px solid #2196f3;
    }
    
    .assistant-message {
        background: #f3e5f5;
        border-left: 4px solid #9c27b0;
    }
    
    .knowledge-card {
        background: #e8f5e8;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #4caf50;
        margin: 0.5rem 0;
    }
    
    .stButton > button {
        background: linear-gradient(45deg, #667eea, #764ba2) !important;
        color: white !important;
        border: none !important;
        border-radius: 25px !important;
        padding: 0.5rem 2rem !important;
    }
</style>
""", unsafe_allow_html=True)

# Configuration
EMBEDDING_API_URL = "http://209.15.123.47:11434/api/embeddings"
EMBEDDING_MODEL = "nomic-embed-text:latest"
OLLAMA_API_URL = "http://209.15.123.47:11434/api/generate"

# Initialize session state for RAG
if "knowledge_base" not in st.session_state:
    st.session_state.knowledge_base = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "rag_db_path" not in st.session_state:
    st.session_state.rag_db_path = "typhoon_rag_knowledge.db"

AVAILABLE_MODELS = {
    "scb10x/typhoon-ocr-7b:latest": {
        "name": "Typhoon OCR 7B",
        "description": "‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç OCR ‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©",
        "icon": "üå™Ô∏è",
        "best_for": "OCR, Document parsing, Thai-English text"
    },
    "qwen2.5:14b": {
        "name": "Qwen2.5 14B", 
        "description": "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà",
        "icon": "üß†",
        "best_for": "General purpose, Complex reasoning"
    },
    "scb10x/llama3.1-typhoon2-8b-instruct:latest": {
        "name": "Typhoon2 8B",
        "description": "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", 
        "icon": "üáπüá≠",
        "best_for": "Thai language, Instructions following"
    }
}

# ==================== RAG SYSTEM FUNCTIONS ====================

class RAGKnowledgeBase:
    def __init__(self, db_path: str = "typhoon_rag_knowledge.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """Initialize SQLite database for knowledge storage"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT NOT NULL,
                content TEXT NOT NULL,
                embedding BLOB,
                chunk_id INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                file_hash TEXT,
                metadata TEXT
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS chat_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT,
                question TEXT,
                answer TEXT,
                context TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def get_embedding(self, text: str) -> Optional[List[float]]:
        """Get embedding from Ollama API"""
        try:
            response = requests.post(
                EMBEDDING_API_URL,
                json={
                    "model": EMBEDDING_MODEL,
                    "prompt": text
                },
                timeout=60
            )
            response.raise_for_status()
            result = response.json()
            return result.get('embedding', [])
        except Exception as e:
            st.error(f"‚ùå Error getting embedding: {str(e)}")
            return None
    
    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """Split text into overlapping chunks"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # Try to break at sentence boundaries
            if end < len(text):
                # Look for sentence endings
                sentence_ends = ['. ', '! ', '? ', '\n\n', '„ÄÇ', 'ÔºÅ', 'Ôºü']
                best_break = end
                
                for i in range(min(100, len(text) - end)):
                    for ending in sentence_ends:
                        if text[end + i:end + i + len(ending)] == ending:
                            best_break = end + i + len(ending)
                            break
                    if best_break != end:
                        break
                
                end = best_break
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap
            if start >= len(text):
                break
                
        return chunks
    
    def add_document(self, filename: str, content: str, metadata: Dict = None) -> bool:
        """Add document to knowledge base"""
        try:
            # Create file hash for deduplication
            file_hash = hashlib.md5(content.encode()).hexdigest()
            
            # Check if document already exists
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT id FROM documents WHERE file_hash = ?", (file_hash,))
            if cursor.fetchone():
                conn.close()
                st.warning(f"‚ö†Ô∏è Document {filename} already exists in knowledge base")
                return False
            
            # Process markdown content
            if filename.endswith('.md'):
                # Convert markdown to plain text for better chunking
                html = markdown.markdown(content)
                # Remove HTML tags
                plain_text = re.sub('<[^<]+?>', '', html)
                content = plain_text
            
            # Chunk the content
            chunks = self.chunk_text(content)
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, chunk in enumerate(chunks):
                status_text.text(f"Processing chunk {i+1}/{len(chunks)}...")
                progress_bar.progress((i + 1) / len(chunks))
                
                # Get embedding
                embedding = self.get_embedding(chunk)
                if embedding:
                    # Store in database
                    cursor.execute('''
                        INSERT INTO documents 
                        (filename, content, embedding, chunk_id, file_hash, metadata)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        filename, 
                        chunk, 
                        pickle.dumps(embedding), 
                        i,
                        file_hash,
                        json.dumps(metadata or {})
                    ))
            
            conn.commit()
            conn.close()
            
            status_text.text(f"‚úÖ Added {len(chunks)} chunks from {filename}")
            progress_bar.progress(1.0)
            return True
            
        except Exception as e:
            st.error(f"‚ùå Error adding document: {str(e)}")
            return False
    
    def search_similar(self, query: str, top_k: int = 5) -> List[Tuple[str, str, float]]:
        """Search for similar content"""
        try:
            query_embedding = self.get_embedding(query)
            if not query_embedding:
                return []
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT filename, content, embedding FROM documents")
            
            results = []
            for filename, content, embedding_blob in cursor.fetchall():
                stored_embedding = pickle.loads(embedding_blob)
                similarity = cosine_similarity(
                    [query_embedding], 
                    [stored_embedding]
                )[0][0]
                results.append((filename, content, similarity))
            
            conn.close()
            
            # Sort by similarity and return top_k
            results.sort(key=lambda x: x[2], reverse=True)
            return results[:top_k]
            
        except Exception as e:
            st.error(f"‚ùå Error searching: {str(e)}")
            return []
    
    def get_stats(self) -> Dict:
        """Get knowledge base statistics"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("SELECT COUNT(DISTINCT filename) FROM documents")
            total_docs = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM documents")
            total_chunks = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM chat_sessions")
            total_chats = cursor.fetchone()[0]
            
            conn.close()
            
            return {
                "total_documents": total_docs,
                "total_chunks": total_chunks,
                "total_chat_sessions": total_chats
            }
        except Exception as e:
            return {"error": str(e)}

def generate_rag_response(query: str, context_docs: List[Tuple[str, str, float]], model: str = "qwen2.5:14b") -> Optional[str]:
    """Generate response using RAG context"""
    try:
        # Prepare context
        context_text = "\n\n".join([
            f"‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ '{doc[0]}':\n{doc[1]}" 
            for doc in context_docs[:3]  # Use top 3 most relevant
        ])
        
        # Create prompt
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Assistant ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:

‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£:
{context_text}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤ ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:"""
        
        # Call API
        response = requests.post(
            OLLAMA_API_URL,
            json={
                "model": model,
                "prompt": prompt,
                "temperature": 0.3,
                "top_p": 0.8,
                "stream": False
            },
            timeout=120
        )
        response.raise_for_status()
        
        result = response.json()
        return result.get('response', '')
        
    except Exception as e:
        st.error(f"‚ùå Error generating RAG response: {str(e)}")
        return None

# ==================== ORIGINAL OCR FUNCTIONS ====================

def check_system_dependencies():
    """Check if system dependencies are available"""
    dependencies = {
        'poppler': False,
        'pdf2image': PDF2IMAGE_AVAILABLE,
        'pymupdf_available': False
    }
    
    # Check for poppler-utils
    try:
        result = subprocess.run(['pdftoppm', '--help'], 
                              capture_output=True, text=True, timeout=5)
        dependencies['poppler'] = result.returncode == 0
    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError):
        dependencies['poppler'] = False
    
    # Check for PyMuPDF as alternative
    try:
        import fitz  # PyMuPDF
        dependencies['pymupdf_available'] = True
    except ImportError:
        dependencies['pymupdf_available'] = False
    
    return dependencies

def convert_pdf_to_images_pypdf2(pdf_file, quality="medium") -> List[Image.Image]:
    """Fallback: Convert PDF to images using PyPDF2 (text extraction only)"""
    try:
        pdf_file.seek(0)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        images = []
        
        # Create a simple text image for each page
        for page_num, page in enumerate(pdf_reader.pages):
            try:
                text = page.extract_text()
                if text.strip():
                    # Create a simple white image with text information
                    img = Image.new('RGB', (800, 1000), color='white')
                    images.append(img)
                else:
                    # Empty page
                    img = Image.new('RGB', (800, 1000), color='white')
                    images.append(img)
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error processing page {page_num + 1}: {str(e)}")
                # Create placeholder image
                img = Image.new('RGB', (800, 1000), color='white')
                images.append(img)
        
        return images
    except Exception as e:
        st.error(f"‚ùå Error using PyPDF2 fallback: {str(e)}")
        return []

def convert_pdf_with_pymupdf(pdf_file, quality="medium") -> List[Image.Image]:
    """Convert PDF using PyMuPDF (fitz)"""
    try:
        import fitz
        
        # Set DPI based on quality
        dpi = {"high": 300, "medium": 200, "low": 150}.get(quality, 200)
        
        pdf_file.seek(0)
        pdf_bytes = pdf_file.read()
        
        # Open PDF from bytes
        pdf_doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        images = []
        
        for page_num in range(pdf_doc.page_count):
            try:
                page = pdf_doc[page_num]
                
                # Create matrix for scaling
                zoom = dpi / 72.0  # 72 DPI is default
                matrix = fitz.Matrix(zoom, zoom)
                
                # Render page to image
                pix = page.get_pixmap(matrix=matrix)
                img_data = pix.tobytes("png")
                
                # Convert to PIL Image
                img = Image.open(BytesIO(img_data))
                images.append(img)
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error processing page {page_num + 1}: {str(e)}")
                # Create placeholder image
                img = Image.new('RGB', (800, 1000), color='white')
                images.append(img)
        
        pdf_doc.close()
        return images
        
    except ImportError:
        st.error("‚ùå PyMuPDF (fitz) not available")
        return []
    except Exception as e:
        st.error(f"‚ùå Error using PyMuPDF: {str(e)}")
        return []

def convert_pdf_to_images(pdf_file, quality="medium") -> List[Image.Image]:
    """Convert PDF to images with multiple fallback methods"""
    
    # Method 1: Try pdf2image with poppler
    if PDF2IMAGE_AVAILABLE:
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                pdf_file.seek(0)
                tmp_file.write(pdf_file.read())
                tmp_file.flush()
                
                # Set DPI based on quality
                dpi = {"high": 300, "medium": 200, "low": 150}.get(quality, 200)
                
                # Try to convert
                images = pdf2image.convert_from_path(tmp_file.name, dpi=dpi)
                
                # Clean up
                os.unlink(tmp_file.name)
                
                if images:
                    st.success(f"‚úÖ PDF converted successfully using pdf2image ({len(images)} pages)")
                    return images
                    
        except Exception as e:
            st.warning(f"‚ö†Ô∏è pdf2image failed: {str(e)}")
            # Clean up temp file if it exists
            try:
                if 'tmp_file' in locals():
                    os.unlink(tmp_file.name)
            except:
                pass
    
    # Method 2: Try PyMuPDF
    st.info("üîÑ Trying alternative PDF converter (PyMuPDF)...")
    images = convert_pdf_with_pymupdf(pdf_file, quality)
    if images:
        st.success(f"‚úÖ PDF converted using PyMuPDF ({len(images)} pages)")
        return images
    
    # Method 3: Fallback to PyPDF2 (text extraction)
    st.warning("‚ö†Ô∏è Using fallback method (PyPDF2) - limited functionality")
    images = convert_pdf_to_images_pypdf2(pdf_file, quality)
    if images:
        st.info(f"‚ÑπÔ∏è PDF processed using PyPDF2 fallback ({len(images)} pages)")
        return images
    
    # If all methods fail
    st.error("‚ùå All PDF conversion methods failed!")
    return []

def extract_text_from_pdf_page(pdf_file, page_num: int) -> str:
    """Extract text from specific PDF page using PyPDF2"""
    try:
        pdf_file.seek(0)
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        
        if page_num < len(pdf_reader.pages):
            page = pdf_reader.pages[page_num]
            return page.extract_text()
        return ""
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Text extraction failed for page {page_num + 1}: {str(e)}")
        return ""

def image_to_base64(image: Image.Image) -> str:
    """Convert PIL image to base64 string"""
    try:
        buffer = BytesIO()
        # Optimize image size
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Resize if too large (max 2048 pixels)
        max_size = 2048
        if max(image.size) > max_size:
            ratio = max_size / max(image.size)
            new_size = tuple(int(dim * ratio) for dim in image.size)
            image = image.resize(new_size, Image.Resampling.LANCZOS)
        
        image.save(buffer, format='PNG', optimize=True)
        return base64.b64encode(buffer.getvalue()).decode()
    except Exception as e:
        st.error(f"‚ùå Error converting image to base64: {str(e)}")
        return ""

def get_ocr_prompt(prompt_type: str, raw_text: str = "") -> str:
    """Get OCR prompt based on type"""
    if prompt_type == "structure":
        return f"""Below is an image of a document page, along with its dimensions and possibly some raw textual content previously extracted from it. 
Note that the text extraction may be incomplete or partially missing. Carefully consider both the layout and any available text to reconstruct the document accurately.
Your task is to return the markdown representation of this document, presenting tables in HTML format as they naturally appear.
If the document contains images or figures, analyze them and include the tag <figure>IMAGE_ANALYSIS</figure> in the appropriate location.
Your final output must be in JSON format with a single key `natural_text` containing the response.
RAW_TEXT_START
{raw_text}
RAW_TEXT_END"""
    else:
        return f"""Below is an image of a document page along with its dimensions. 
Simply return the markdown representation of this document, presenting tables in markdown format as they naturally appear.
If the document contains images, use a placeholder like dummy.png for each image.
Your final output must be in JSON format with a single key `natural_text` containing the response.
RAW_TEXT_START
{raw_text}
RAW_TEXT_END"""

def call_ollama_api(model: str, prompt: str, image_base64: str, params: dict) -> Optional[str]:
    """Call Ollama API for OCR processing with error handling"""
    try:
        # Validate inputs
        if not image_base64:
            raise ValueError("Empty image data")
        
        # For OCR models, we need to use chat completion format
        if "typhoon-ocr" in model:
            payload = {
                "model": model,
                "prompt": prompt,
                "images": [image_base64],
                "temperature": params.get('temperature', 0.1),
                "top_p": params.get('top_p', 0.6),
                "num_predict": params.get('max_tokens', 12000),
                "stream": False
            }
        else:
            # For other models, use standard format
            payload = {
                "model": model,
                "prompt": f"Analyze this image and extract all text content. Return the result in markdown format.\n\nImage: data:image/png;base64,{image_base64}\n\n{prompt}",
                "temperature": params.get('temperature', 0.1),
                "top_p": params.get('top_p', 0.6),
                "num_predict": params.get('max_tokens', 12000),
                "stream": False
            }
        
        # Add timeout and retry logic
        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    OLLAMA_API_URL, 
                    json=payload, 
                    timeout=300,  # 5 minutes timeout
                    headers={'Content-Type': 'application/json'}
                )
                response.raise_for_status()
                
                result = response.json()
                content = result.get('response', '')
                
                if content.strip():
                    return content
                else:
                    raise ValueError("Empty response from API")
                    
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    st.warning(f"‚ö†Ô∏è Timeout on attempt {attempt + 1}, retrying...")
                    continue
                else:
                    raise
            except requests.exceptions.ConnectionError:
                if attempt < max_retries - 1:
                    st.warning(f"‚ö†Ô∏è Connection error on attempt {attempt + 1}, retrying...")
                    continue
                else:
                    raise
        
    except requests.exceptions.RequestException as e:
        error_msg = f"API Request Error: {str(e)}"
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_detail = e.response.json()
                error_msg += f" - {error_detail}"
            except:
                error_msg += f" - HTTP {e.response.status_code}"
        st.error(f"‚ùå {error_msg}")
        return None
    except ValueError as e:
        st.error(f"‚ùå Validation Error: {str(e)}")
        return None
    except Exception as e:
        st.error(f"‚ùå Processing Error: {str(e)}")
        st.error(f"Debug: {traceback.format_exc()}")
        return None

def process_single_document(file, model: str, params: dict) -> Dict[str, Any]:
    """Process a single document with comprehensive error handling"""
    results = {
        'filename': file.name,
        'file_type': file.type,
        'file_size': file.size,
        'pages': [],
        'total_pages': 0,
        'success': False,
        'error': None,
        'warnings': []
    }
    
    try:
        # Validate file size (max 10MB)
        max_size = 10 * 1024 * 1024  # 10MB
        if file.size > max_size:
            results['error'] = f"File too large ({file.size/1024/1024:.1f}MB). Maximum size is 10MB."
            return results
        
        # Handle different file types
        if file.type == 'application/pdf':
            st.info(f"üìÑ Processing PDF: {file.name}")
            images = convert_pdf_to_images(file, params.get('image_quality', 'medium'))
            results['total_pages'] = len(images) if images else 0
            
            if not images:
                results['error'] = "Could not convert PDF to images"
                return results
                
        elif file.type.startswith('image/'):
            st.info(f"üñºÔ∏è Processing Image: {file.name}")
            try:
                image = Image.open(file)
                images = [image]
                results['total_pages'] = 1
            except Exception as e:
                results['error'] = f"Could not open image file: {str(e)}"
                return results
        else:
            results['error'] = f"Unsupported file type: {file.type}"
            return results
        
        # Process each page/image
        for i, image in enumerate(images):
            page_result = {
                'page_number': i + 1,
                'success': False,
                'content': '',
                'raw_response': '',
                'extracted_text': '',
                'processing_time': 0,
                'error': None
            }
            
            try:
                import time
                start_time = time.time()
                
                # For PDF pages, try to extract text first
                if file.type == 'application/pdf':
                    try:
                        page_result['extracted_text'] = extract_text_from_pdf_page(file, i)
                    except:
                        pass
                
                # Convert image to base64
                image_base64 = image_to_base64(image)
                if not image_base64:
                    page_result['error'] = "Failed to convert image to base64"
                    continue
                
                # Get appropriate prompt
                prompt = get_ocr_prompt(
                    params.get('prompt_type', 'default'),
                    page_result['extracted_text']
                )
                
                # Show processing status
                with st.spinner(f"üîÑ Processing page {i + 1}..."):
                    # Call API
                    response = call_ollama_api(model, prompt, image_base64, params)
                
                if response:
                    page_result['raw_response'] = response
                    page_result['processing_time'] = time.time() - start_time
                    
                    # Try to parse JSON response
                    try:
                        json_response = json.loads(response)
                        page_result['content'] = json_response.get('natural_text', response)
                    except json.JSONDecodeError:
                        page_result['content'] = response
                    
                    # Validate content
                    if page_result['content'].strip():
                        page_result['success'] = True
                        st.success(f"‚úÖ Page {i + 1} processed successfully ({page_result['processing_time']:.1f}s)")
                    else:
                        page_result['error'] = "Empty content returned"
                        st.warning(f"‚ö†Ô∏è Page {i + 1} returned empty content")
                else:
                    page_result['error'] = "No response from API"
                    st.error(f"‚ùå Page {i + 1} failed - no response")
                
            except Exception as e:
                page_result['error'] = str(e)
                page_result['processing_time'] = time.time() - start_time if 'start_time' in locals() else 0
                st.error(f"‚ùå Page {i + 1} failed: {str(e)}")
            
            results['pages'].append(page_result)
        
        # Check if any pages were successful
        successful_pages = [p for p in results['pages'] if p['success']]
        results['success'] = len(successful_pages) > 0
        
        if results['success']:
            results['summary'] = {
                'successful_pages': len(successful_pages),
                'failed_pages': len(results['pages']) - len(successful_pages),
                'total_processing_time': sum(p['processing_time'] for p in results['pages']),
                'average_time_per_page': sum(p['processing_time'] for p in results['pages']) / len(results['pages']) if results['pages'] else 0
            }
        
    except Exception as e:
        results['error'] = f"Document processing failed: {str(e)}"
        st.error(f"‚ùå Fatal error processing {file.name}: {str(e)}")
    
    return results

def process_documents(uploaded_files, model: str, params: dict):
    """Process uploaded documents with enhanced error handling and progress tracking"""
    
    # Handle single file vs multiple files
    files_to_process = uploaded_files if isinstance(uploaded_files, list) else [uploaded_files]
    
    st.header("üîÑ Processing Results")
    
    # Show system status first
    deps = check_system_dependencies()
    
    with st.expander("üîß System Status", expanded=False):
        st.write("**Dependencies Status:**")
        status_items = [
            ("Poppler (PDF2Image)", "‚úÖ" if deps['poppler'] else "‚ùå"),
            ("pdf2image Library", "‚úÖ" if deps['pdf2image'] else "‚ùå"),
            ("PyMuPDF Alternative", "‚úÖ" if deps['pymupdf_available'] else "‚ùå"),
            ("PyPDF2 Fallback", "‚úÖ")  # Always available
        ]
        
        for item, status in status_items:
            st.write(f"{status} {item}")
        
        if not deps['poppler'] and not deps['pymupdf_available']:
            st.warning("‚ö†Ô∏è Limited PDF processing capabilities. Consider installing poppler or PyMuPDF.")
    
    # Progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    all_results = []
    total_files = len(files_to_process)
    
    for i, file in enumerate(files_to_process):
        status_text.text(f"üìÑ Processing {file.name} ({i+1}/{total_files})...")
        progress_bar.progress(i / total_files)
        
        # Reset file pointer
        file.seek(0)
        
        # Process document
        result = process_single_document(file, model, params)
        all_results.append(result)
        
        # Display results for this file
        status_emoji = "‚úÖ" if result['success'] else "‚ùå"
        summary_text = ""
        
        if result['success'] and 'summary' in result:
            s = result['summary']
            summary_text = f" - {s['successful_pages']}/{result['total_pages']} pages, {s['total_processing_time']:.1f}s total"
        
        with st.expander(f"{status_emoji} {file.name}{summary_text}", expanded=result['success']):
            if result['success']:
                # Show summary
                if 'summary' in result:
                    s = result['summary']
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("‚úÖ Success", f"{s['successful_pages']}/{result['total_pages']}")
                    with col2:
                        st.metric("‚è±Ô∏è Total Time", f"{s['total_processing_time']:.1f}s")
                    with col3:
                        st.metric("üìä Avg/Page", f"{s['average_time_per_page']:.1f}s")
                    with col4:
                        st.metric("üìÑ File Size", f"{result['file_size']/1024:.1f}KB")
                
                # RAG Integration - Auto-add to knowledge base option
                if st.button(f"üß† Add to Knowledge Base", key=f"add_kb_{i}"):
                    # Combine all successful page content
                    combined_content = "\n\n".join([
                        page['content'] for page in result['pages'] if page['success']
                    ])
                    
                    # Add to RAG knowledge base
                    kb = RAGKnowledgeBase(st.session_state.rag_db_path)
                    success = kb.add_document(
                        filename=file.name,
                        content=combined_content,
                        metadata={
                            "processing_time": s.get('total_processing_time', 0),
                            "model_used": model,
                            "successful_pages": s.get('successful_pages', 0)
                        }
                    )
                    if success:
                        st.success(f"‚úÖ Added {file.name} to knowledge base!")
                        st.rerun()
                
                # Show results for each page
                for page in result['pages']:
                    if page['success']:
                        st.subheader(f"üìÑ Page {page['page_number']}")
                        
                        # Tabs for different views
                        tab1, tab2, tab3, tab4 = st.tabs(["üìñ Preview", "üìù Markdown", "üîß Raw", "‚ÑπÔ∏è Info"])
                        
                        with tab1:
                            if params.get('output_format') == 'html':
                                st.markdown(page['content'], unsafe_allow_html=True)
                            else:
                                st.markdown(page['content'])
                        
                        with tab2:
                            st.code(page['content'], language='markdown')
                        
                        with tab3:
                            st.code(page['raw_response'], language='json')
                        
                        with tab4:
                            st.write(f"**Processing Time:** {page['processing_time']:.1f}s")
                            st.write(f"**Content Length:** {len(page['content'])} characters")
                            if page['extracted_text']:
                                st.write(f"**Extracted Text Length:** {len(page['extracted_text'])} characters")
                            
                        # Download button
                        file_extension = {
                            'markdown': 'md',
                            'html': 'html', 
                            'json': 'json'
                        }.get(params.get('output_format', 'markdown'), 'md')
                        
                        st.download_button(
                            f"üíæ Download Page {page['page_number']}",
                            page['content'],
                            f"{file.name}_page_{page['page_number']}.{file_extension}",
                            f"text/{file_extension}"
                        )
                    else:
                        st.error(f"‚ùå Page {page['page_number']} failed: {page.get('error', 'Unknown error')}")
                        if page.get('processing_time', 0) > 0:
                            st.write(f"Processing time: {page['processing_time']:.1f}s")
            else:
                st.error(f"‚ùå Failed to process {file.name}")
                if result.get('error'):
                    st.write(f"**Error:** {result['error']}")
                
                # Show system recommendations
                if 'pdf' in file.type.lower() and not deps['poppler'] and not deps['pymupdf_available']:
                    st.info("""
                    **üí° Recommendation for PDF processing:**
                    
                    For better PDF support, install one of these:
                    
                    **Option 1: Install Poppler (Recommended)**
                    ```bash
                    # Ubuntu/Debian
                    apt-get install poppler-utils
                    
                    # CentOS/RHEL
                    yum install poppler-utils
                    
                    # macOS
                    brew install poppler
                    ```
                    
                    **Option 2: Install PyMuPDF**
                    ```bash
                    pip install PyMuPDF
                    ```
                    """)
    
    # Final progress
    progress_bar.progress(1.0)
    status_text.text("üéâ Processing complete!")
    
    # Summary statistics
    successful_files = sum(1 for r in all_results if r['success'])
    total_pages = sum(r['total_pages'] for r in all_results)
    successful_pages = sum(len([p for p in r['pages'] if p['success']]) for r in all_results)
    total_processing_time = sum(
        r.get('summary', {}).get('total_processing_time', 0) for r in all_results if r['success']
    )
    
    # Display final summary
    st.markdown("---")
    st.subheader("üìä Processing Summary")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìÅ Files", f"{successful_files}/{len(files_to_process)}")
    with col2:
        st.metric("üìÑ Pages", f"{successful_pages}/{total_pages}")
    with col3:
        st.metric("‚è±Ô∏è Total Time", f"{total_processing_time:.1f}s")
    with col4:
        st.metric("ü§ñ Model", AVAILABLE_MODELS[model]['name'])
    
    # Show processing efficiency
    if successful_pages > 0:
        avg_time_per_page = total_processing_time / successful_pages
        pages_per_minute = 60 / avg_time_per_page if avg_time_per_page > 0 else 0
        
        st.info(f"""
        **‚ö° Performance Metrics:**
        - Average processing time: **{avg_time_per_page:.1f} seconds per page**
        - Processing rate: **{pages_per_minute:.1f} pages per minute**
        - Success rate: **{(successful_pages/total_pages)*100:.1f}%**
        """)
    
    # Bulk download for successful results
    if successful_pages > 0:
        # Combine all successful content
        combined_content = f"# Typhoon OCR Results\n\n"
        combined_content += f"**Processing Summary:**\n"
        combined_content += f"- Files processed: {successful_files}/{len(files_to_process)}\n"
        combined_content += f"- Pages processed: {successful_pages}/{total_pages}\n"
        combined_content += f"- Model used: {AVAILABLE_MODELS[model]['name']}\n"
        combined_content += f"- Total processing time: {total_processing_time:.1f}s\n\n"
        combined_content += f"---\n\n"
        
        for result in all_results:
            if result['success']:
                combined_content += f"# üìÑ {result['filename']}\n\n"
                if 'summary' in result:
                    s = result['summary']
                    combined_content += f"**File Summary:**\n"
                    combined_content += f"- Pages: {s['successful_pages']}/{result['total_pages']}\n"
                    combined_content += f"- Processing time: {s['total_processing_time']:.1f}s\n\n"
                
                for page in result['pages']:
                    if page['success']:
                        combined_content += f"## Page {page['page_number']}\n\n"
                        combined_content += f"{page['content']}\n\n"
                        combined_content += f"---\n\n"
        
        # File extension based on output format
        file_extension = {
            'markdown': 'md',
            'html': 'html', 
            'json': 'json'
        }.get(params.get('output_format', 'markdown'), 'md')
        
        col1, col2 = st.columns([1, 1])
        with col1:
            st.download_button(
                "üì¶ Download All Results",
                combined_content,
                f"typhoon_ocr_results.{file_extension}",
                f"text/{file_extension}",
                help=f"Download combined results in {params.get('output_format', 'markdown')} format"
            )
        
        with col2:
            if st.button("üß† Add All to Knowledge Base"):
                kb = RAGKnowledgeBase(st.session_state.rag_db_path)
                added_count = 0
                for result in all_results:
                    if result['success']:
                        combined_content = "\n\n".join([
                            page['content'] for page in result['pages'] if page['success']
                        ])
                        if kb.add_document(
                            filename=result['filename'],
                            content=combined_content,
                            metadata={"batch_processed": True}
                        ):
                            added_count += 1
                
                if added_count > 0:
                    st.success(f"‚úÖ Added {added_count} documents to knowledge base!")
                    st.rerun()

def main():
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>üå™Ô∏è Typhoon OCR with RAG</h1>
        <p>AI-Powered Thai-English Document Parser + Knowledge Q&A</p>
        <p>Powered by SCB 10X with AI NT North Team</p>
    </div>
    """, unsafe_allow_html=True)

    # System status check
    deps = check_system_dependencies()
    
    # Show system warnings if needed
    if not deps['poppler'] and not deps['pymupdf_available']:
        st.markdown("""
        <div class="warning-message">
            <strong>‚ö†Ô∏è Limited PDF Processing Capability</strong><br>
            For optimal PDF processing, please install poppler-utils or PyMuPDF.<br>
            Currently using PyPDF2 fallback which has limited functionality.
        </div>
        """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è Settings")
        
        # System status in sidebar
        with st.expander("üîß System Status"):
            st.write("**PDF Processing:**")
            if deps['poppler'] and deps['pdf2image']:
                st.success("‚úÖ Full PDF support (pdf2image + poppler)")
            elif deps['pymupdf_available']:
                st.info("‚ÑπÔ∏è Good PDF support (PyMuPDF)")
            else:
                st.warning("‚ö†Ô∏è Basic PDF support (PyPDF2 only)")
            
        # RAG Knowledge Base Status
        kb = RAGKnowledgeBase(st.session_state.rag_db_path)
        stats = kb.get_stats()
        
        st.header("üß† Knowledge Base")
        if not stats.get("error"):
            col1, col2 = st.columns(2)
            with col1:
                st.metric("üìö Documents", stats["total_documents"])
            with col2:
                st.metric("üìÑ Chunks", stats["total_chunks"])
            st.metric("üí¨ Chat Sessions", stats["total_chat_sessions"])
        else:
            st.error("‚ùå Knowledge base error")
        
        # Model selection
        st.subheader("ü§ñ Model Selection")
        selected_model = st.selectbox(
            "Choose AI Model:",
            options=list(AVAILABLE_MODELS.keys()),
            format_func=lambda x: f"{AVAILABLE_MODELS[x]['icon']} {AVAILABLE_MODELS[x]['name']}"
        )
        
        # Display model info
        model_info = AVAILABLE_MODELS[selected_model]
        st.info(f"**{model_info['name']}**\n\n{model_info['description']}\n\n**Best for:** {model_info['best_for']}")
        
        # Processing parameters
        st.subheader("üéØ Processing Parameters")
        temperature = st.slider("Temperature", 0.0, 1.0, 0.1, 0.1, help="Lower = more accurate, Higher = more creative")
        top_p = st.slider("Top P", 0.0, 1.0, 0.6, 0.1, help="Controls randomness of word selection")
        max_tokens = st.slider("Max Tokens", 1000, 16384, 12000, 500, help="Maximum length of generated text")
        
        # OCR specific settings
        st.subheader("üìÑ OCR Settings")
        prompt_type = st.selectbox(
            "Prompt Type:",
            ["default", "structure"],
            format_func=lambda x: "Default (Simple)" if x == "default" else "Structure (Complex Documents)",
            help="Structure mode better for tables, charts, and complex layouts"
        )
        
        output_format = st.selectbox(
            "Output Format:",
            ["markdown", "html", "json"],
            help="Choose output format - HTML best for tables, JSON for data processing"
        )
        
        # Advanced settings
        with st.expander("üîß Advanced Settings"):
            repetition_penalty = st.slider(
                "Repetition Penalty", 
                1.0, 2.0, 1.2, 0.1,
                help="Higher values reduce repetitive text"
            )
            image_quality = st.selectbox(
                "Image Quality", 
                ["high", "medium", "low"],
                index=1,
                help="Higher quality = better accuracy but slower processing"
            )
            batch_processing = st.checkbox(
                "Enable Batch Processing",
                help="Process multiple files at once"
            )
            
            # File size limit info
            st.info("üìè **File Limits:**\n- Max file size: 10MB\n- Supported: PDF, PNG, JPG, JPEG")

    # ===== Main content area with Tabs =====
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìÅ Upload & OCR", 
        "üß† Knowledge Base", 
        "üí¨ AI Chat", 
        "‚ú® Features", 
        "üìñ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
    ])

    # ---- Tab 1: Upload & Process (Original OCR) ----
    with tab1:
        st.header("üìÅ Upload Document for OCR")

        # File upload
        uploaded_files = st.file_uploader(
            "Choose files",
            type=['pdf', 'png', 'jpg', 'jpeg'],
            accept_multiple_files=batch_processing,
            help="Support: PDF, PNG, JPG, JPEG (Max: 10MB per file)"
        )
        
        # Preview uploaded files
        if uploaded_files:
            if isinstance(uploaded_files, list):
                total_size = sum(file.size for file in uploaded_files)
                st.success(f"‚úÖ {len(uploaded_files)} files uploaded ({total_size/1024/1024:.1f}MB total)")
                
                # Show file details
                for i, file in enumerate(uploaded_files[:5]):  # Show first 5
                    size_mb = file.size / 1024 / 1024
                    st.write(f"{i+1}. **{file.name}** ({size_mb:.1f}MB, {file.type})")
                    
                if len(uploaded_files) > 5:
                    st.write(f"... and {len(uploaded_files) - 5} more files")
                    
            else:
                size_mb = uploaded_files.size / 1024 / 1024
                st.success(f"‚úÖ File uploaded: **{uploaded_files.name}** ({size_mb:.1f}MB)")
                
                # Show preview for single file
                if uploaded_files.type.startswith('image'):
                    try:
                        image = Image.open(uploaded_files)
                        st.image(image, caption="Uploaded Image", use_column_width=True)
                    except Exception as e:
                        st.error(f"‚ùå Cannot preview image: {str(e)}")
                elif uploaded_files.type == 'application/pdf':
                    st.info("üìÑ PDF file uploaded - preview will be shown during processing")
        
        # Process button with validation
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if st.button("üöÄ Process Document(s)", type="primary", disabled=not uploaded_files):
                if uploaded_files:
                    # Validate total processing load
                    files_to_check = uploaded_files if isinstance(uploaded_files, list) else [uploaded_files]
                    total_size = sum(file.size for file in files_to_check)
                    
                    # Warn for large processing jobs
                    if total_size > 50 * 1024 * 1024:  # 50MB
                        st.warning("‚ö†Ô∏è Large file size detected. Processing may take several minutes.")
                    
                    if len(files_to_check) > 5:
                        st.warning("‚ö†Ô∏è Processing multiple files. This may take some time.")
                    
                    # Start processing
                    try:
                        process_documents(uploaded_files, selected_model, {
                            'temperature': temperature,
                            'top_p': top_p,
                            'max_tokens': max_tokens,
                            'repetition_penalty': repetition_penalty,
                            'prompt_type': prompt_type,
                            'output_format': output_format,
                            'image_quality': image_quality
                        })
                    except Exception as e:
                        st.error(f"‚ùå Processing failed: {str(e)}")
                        st.error("Please check the error logs above and try again.")
                else:
                    st.error("‚ùå Please upload at least one file!")
        
        with col2:
            if st.button("üîÑ Clear Files"):
                st.rerun()

    # ---- Tab 2: Knowledge Base Management ----
    with tab2:
        st.header("üß† Knowledge Base Management")
        
        kb = RAGKnowledgeBase(st.session_state.rag_db_path)
        stats = kb.get_stats()
        
        # Display stats
        if not stats.get("error"):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìö Total Documents", stats["total_documents"])
            with col2:
                st.metric("üìÑ Total Chunks", stats["total_chunks"])
            with col3:
                st.metric("üí¨ Chat Sessions", stats["total_chat_sessions"])
        
        st.markdown("---")
        
        # Add documents manually
        st.subheader("üì§ Add Documents to Knowledge Base")
        
        # Method 1: Upload Markdown files
        st.write("**Method 1: Upload Markdown Files**")
        markdown_files = st.file_uploader(
            "Upload Markdown files",
            type=['md', 'txt'],
            accept_multiple_files=True,
            help="Upload .md or .txt files to add to knowledge base"
        )
        
        if markdown_files and st.button("‚ûï Add Markdown Files"):
            added_count = 0
            for file in markdown_files:
                try:
                    content = file.read().decode('utf-8')
                    if kb.add_document(
                        filename=file.name,
                        content=content,
                        metadata={"source": "manual_upload", "file_type": "markdown"}
                    ):
                        added_count += 1
                except Exception as e:
                    st.error(f"‚ùå Error adding {file.name}: {str(e)}")
            
            if added_count > 0:
                st.success(f"‚úÖ Added {added_count} markdown files to knowledge base!")
                st.rerun()
        
        # Method 2: Direct text input
        st.write("**Method 2: Direct Text Input**")
        with st.form("add_text_form"):
            doc_title = st.text_input("Document Title", placeholder="Enter document title")
            doc_content = st.text_area(
                "Document Content",
                height=200,
                placeholder="Paste or type your document content here..."
            )
            
            submitted = st.form_submit_button("‚ûï Add to Knowledge Base")
            if submitted and doc_title and doc_content:
                if kb.add_document(
                    filename=f"{doc_title}.md",
                    content=doc_content,
                    metadata={"source": "manual_input"}
                ):
                    st.success(f"‚úÖ Added '{doc_title}' to knowledge base!")
                    st.rerun()
        
        st.markdown("---")
        
        # Knowledge base browser
        st.subheader("üìñ Browse Knowledge Base")
        
        if stats.get("total_documents", 0) > 0:
            # Get document list
            conn = sqlite3.connect(st.session_state.rag_db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT DISTINCT filename, COUNT(*) as chunk_count, MAX(created_at) as latest FROM documents GROUP BY filename ORDER BY latest DESC")
            docs = cursor.fetchall()
            conn.close()
            
            # Display documents
            for filename, chunk_count, created_at in docs:
                with st.expander(f"üìÑ {filename} ({chunk_count} chunks)"):
                    st.write(f"**Created:** {created_at}")
                    st.write(f"**Chunks:** {chunk_count}")
                    
                    # Show first chunk as preview
                    conn = sqlite3.connect(st.session_state.rag_db_path)
                    cursor = conn.cursor()
                    cursor.execute("SELECT content FROM documents WHERE filename = ? LIMIT 1", (filename,))
                    preview = cursor.fetchone()
                    if preview:
                        st.write("**Preview:**")
                        st.text(preview[0][:200] + "..." if len(preview[0]) > 200 else preview[0])
                    conn.close()
                    
                    # Delete button
                    if st.button(f"üóëÔ∏è Delete {filename}", key=f"del_{filename}"):
                        conn = sqlite3.connect(st.session_state.rag_db_path)
                        cursor = conn.cursor()
                        cursor.execute("DELETE FROM documents WHERE filename = ?", (filename,))
                        conn.commit()
                        conn.close()
                        st.success(f"‚úÖ Deleted {filename}")
                        st.rerun()
        else:
            st.info("üìù No documents in knowledge base yet. Add some documents to get started!")

    # ---- Tab 3: AI Chat with RAG ----
    with tab3:
        st.header("üí¨ AI Chat with Knowledge Base")
        
        # Check if knowledge base has content
        if stats.get("total_documents", 0) == 0:
            st.warning("‚ö†Ô∏è No documents in knowledge base. Please add documents in the Knowledge Base tab first.")
            return
        
        # Chat interface
        st.subheader("üó£Ô∏è Ask Questions About Your Documents")
        
        # Display chat history
        for i, (question, answer, context) in enumerate(st.session_state.chat_history):
            # User message
            st.markdown(f"""
            <div class="chat-message user-message">
                <strong>ü§î You:</strong><br>
                {question}
            </div>
            """, unsafe_allow_html=True)
            
            # Assistant message
            st.markdown(f"""
            <div class="chat-message assistant-message">
                <strong>ü§ñ Assistant:</strong><br>
                {answer}
            </div>
            """, unsafe_allow_html=True)
            
            # Show context sources
            if context:
                with st.expander(f"üìö Sources (Chat {i+1})", expanded=False):
                    for j, (filename, content, similarity) in enumerate(context):
                        st.markdown(f"""
                        <div class="knowledge-card">
                            <strong>üìÑ {filename}</strong> (Similarity: {similarity:.3f})<br>
                            <em>{content[:200]}...</em>
                        </div>
                        """, unsafe_allow_html=True)
        
        # Chat input
        with st.form("chat_form", clear_on_submit=True):
            user_question = st.text_input(
                "Ask a question:",
                placeholder="What would you like to know about your documents?",
                key="chat_input"
            )
            
            col1, col2, col3 = st.columns([1, 1, 4])
            with col1:
                ask_button = st.form_submit_button("üöÄ Ask")
            with col2:
                clear_button = st.form_submit_button("üóëÔ∏è Clear Chat")
            
            if clear_button:
                st.session_state.chat_history = []
                st.rerun()
        
        if ask_button and user_question:
            with st.spinner("üîç Searching knowledge base and generating response..."):
                # Search for relevant context
                context_docs = kb.search_similar(user_question, top_k=5)
                
                if context_docs:
                    # Generate RAG response
                    response = generate_rag_response(
                        user_question, 
                        context_docs, 
                        selected_model
                    )
                    
                    if response:
                        # Add to chat history
                        st.session_state.chat_history.append((
                            user_question,
                            response,
                            context_docs[:3]  # Store top 3 for context
                        ))
                        
                        # Save to database
                        conn = sqlite3.connect(st.session_state.rag_db_path)
                        cursor = conn.cursor()
                        cursor.execute('''
                            INSERT INTO chat_sessions (session_id, question, answer, context)
                            VALUES (?, ?, ?, ?)
                        ''', (
                            "default",  # Simple session management
                            user_question,
                            response,
                            json.dumps([(doc[0], doc[1][:200], doc[2]) for doc in context_docs[:3]])
                        ))
                        conn.commit()
                        conn.close()
                        
                        st.rerun()
                    else:
                        st.error("‚ùå Failed to generate response")
                else:
                    st.warning("‚ö†Ô∏è No relevant information found in knowledge base")

    # ---- Tab 4: Features ----
    with tab4:
        st.header("‚ú® Enhanced Features with RAG")
        
        # Enhanced feature cards
        features = [
            {
                "icon": "üå™Ô∏è",
                "title": "Advanced OCR Processing",
                "description": "‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ AI ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢",
                "items": [
                    "Thai-English OCR with high accuracy",
                    "Complex document structure recognition", 
                    "Batch processing for multiple files",
                    "Multiple output formats (MD, HTML, JSON)"
                ]
            },
            {
                "icon": "üß†", 
                "title": "RAG Knowledge Base",
                "description": "‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞",
                "items": [
                    "Auto-import OCR results to knowledge base",
                    "Manual markdown document upload",
                    "Intelligent text chunking and embedding",
                    "Semantic search with similarity scoring"
                ]
            },
            {
                "icon": "üí¨",
                "title": "AI-Powered Q&A",
                "description": "‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ AI",
                "items": [
                    "Context-aware responses from your documents",
                    "Multi-language support (Thai-English)",
                    "Source attribution and transparency",
                    "Chat history and session management"
                ]
            },
            {
                "icon": "üìä",
                "title": "Document Analytics", 
                "description": "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°",
                "items": [
                    "Processing performance metrics",
                    "Knowledge base statistics",
                    "Document similarity analysis",
                    "Content organization and retrieval"
                ]
            }
        ]
        
        for feature in features:
            st.markdown(f"""
            <div class="feature-card">
                <h3>{feature['icon']} {feature['title']}</h3>
                <p>{feature['description']}</p>
                <ul>
                    {' '.join([f'<li>‚úì {item}</li>' for item in feature['items']])}
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        # Workflow diagram
        st.subheader("üîÑ Enhanced Workflow")
        st.markdown("""
        ```mermaid
        graph TD
            A[üìÑ Upload Document] --> B[üå™Ô∏è OCR Processing]
            B --> C[üìù Extract Text/Markdown]
            C --> D{Add to Knowledge Base?}
            D -->|Yes| E[üß† Store in RAG DB]
            D -->|No| F[üíæ Download Results]
            E --> G[üí¨ AI Chat Ready]
            G --> H[üîç Ask Questions]
            H --> I[ü§ñ Context-Aware Answers]
            
            J[üì§ Manual Upload] --> E
            K[‚úçÔ∏è Direct Input] --> E
        ```
        """)
        
        # Performance comparison
        st.subheader("‚ö° Model Performance Comparison")
        
        performance_data = {
            "Model": ["Typhoon OCR 7B", "Qwen2.5 14B", "Typhoon2 8B"],
            "Thai OCR": ["‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê"],
            "English OCR": ["‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê"],
            "Complex Tables": ["‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê"],
            "Thai Q&A": ["‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê"],
            "Processing Speed": ["‚≠ê‚≠ê‚≠ê‚≠ê", "‚≠ê‚≠ê", "‚≠ê‚≠ê‚≠ê‚≠ê"],
            "Best For": ["OCR Tasks", "RAG Q&A", "Thai Content"]
        }
        
        st.table(performance_data)
        
        # RAG Benefits
        st.subheader("üéØ RAG System Benefits")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **üìö Knowledge Management:**
            - Persistent document storage
            - Intelligent text chunking
            - Semantic search capabilities
            - Multi-document correlation
            
            **üîç Smart Retrieval:**
            - Context-aware responses
            - Source attribution
            - Similarity scoring
            - Multi-language support
            """)
        
        with col2:
            st.markdown("""
            **‚ö° Efficiency Gains:**
            - Instant document lookup
            - Automated knowledge base building
            - Batch processing integration
            - Scalable architecture
            
            **üéØ Use Cases:**
            - Corporate document Q&A
            - Research paper analysis
            - Legal document review
            - Technical documentation
            """)

    # ---- Tab 5: User Guide ----
    with tab5:
        st.header("üìñ ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Typhoon OCR with RAG")
        
        st.markdown("""
## üåü ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß

Typhoon OCR with RAG ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° **OCR ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á** ‡∏Å‡∏±‡∏ö **RAG (Retrieval-Augmented Generation)** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:

1. **üìÑ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£** - ‡πÅ‡∏õ‡∏•‡∏á PDF/‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
2. **üß† ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ** - ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö
3. **üí¨ ‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞** - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£

---

## üîÑ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: OCR Processing
1. **‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏ó‡πá‡∏ö "üìÅ Upload & OCR"**
2. **‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå** (PDF, PNG, JPG, JPEG)
3. **‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå** ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
4. **‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "üöÄ Process Document(s)"**
5. **‡∏£‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå** ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ Knowledge Base
‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å OCR ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏°‡∏µ **3 ‡∏ß‡∏¥‡∏ò‡∏µ** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ Knowledge Base:

#### üîπ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: Auto-add ‡∏à‡∏≤‡∏Å‡∏ú‡∏• OCR
- ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å OCR ‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏à‡∏∞‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏° **"üß† Add to Knowledge Base"**
- ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

#### üîπ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: Upload Markdown Files
- ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö **"üß† Knowledge Base"**
- ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô **"Method 1: Upload Markdown Files"**
- ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå .md ‡∏´‡∏£‡∏∑‡∏≠ .txt
- ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° **"‚ûï Add Markdown Files"**

#### üîπ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: Direct Text Input
- ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô **"Method 2: Direct Text Input"**
- ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
- ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° **"‚ûï Add to Knowledge Base"**

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ AI
1. **‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö "üí¨ AI Chat"**
2. **‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** ‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á "Ask a question"
3. **‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "üöÄ Ask"**
4. **‡∏£‡∏≠‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö** ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

---

## üéØ ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå

### üìä ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OCR (‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£)
- **Temperature: 0.1** ‚Üí ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
- **Top P: 0.6** ‚Üí ‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
- **Model: Typhoon OCR 7B** ‚Üí ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô OCR

### üí¨ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Q&A (‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö)
- **Temperature: 0.3** ‚Üí ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
- **Model: Qwen2.5 14B** ‚Üí ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
- **Model: Typhoon2 8B** ‚Üí ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

---

## üß† RAG Knowledge Base ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

**RAG (Retrieval-Augmented Generation)** ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ AI ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:

### üîç ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á RAG:
1. **‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** ‚Üí ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏¥‡πâ‡∏ô‡πÄ‡∏•‡πá‡∏Å (chunks)
2. **‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings** ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à
3. **‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞** ‚Üí ‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ Semantic Search
4. **‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** ‚Üí ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö

### üí° ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á RAG:
- ‚úÖ **‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥** ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á
- ‚úÖ **‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á** ‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™
- ‚úÖ **‡πÑ‡∏°‡πà Hallucination** ‡πÑ‡∏°‡πà‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á
- ‚úÖ **‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î** ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢ ‡πÜ

---

## üì± ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÅ‡∏ó‡πá‡∏ö

### üìÅ Upload & OCR
- **‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå:** ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
- **‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:** PDF, PNG, JPG, JPEG (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10MB)
- **‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ:** ‡πÉ‡∏ä‡πâ "Structure mode" ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ï‡∏≤‡∏£‡∏≤‡∏á

### üß† Knowledge Base  
- **‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå:** ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ
- **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å:**
  - ‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
  - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà
  - ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
  - ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£

### üí¨ AI Chat
- **‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå:** ‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
- **‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏©:**
  - ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
  - ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Similarity
  - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Chat History
  - ‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ

---

## ‚ö° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### üéØ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û OCR:
1. **‡∏™‡πÅ‡∏Å‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏π‡∏á** (300 DPI ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ)
2. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏™‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°** ‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏á‡∏≤
3. **‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡∏£‡∏á** ‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏µ‡∏¢‡∏á
4. **‡πÉ‡∏ä‡πâ "Structure mode"** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô

### üß† ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Knowledge Base:
1. **‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏ç‡πà** ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏¢‡πà‡∏≠‡∏¢ ‡πÜ
2. **‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢** ‡πÄ‡∏ä‡πà‡∏ô "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô_Q1_2024.md"
3. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
4. **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞ ‡∏•‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

### üí¨ ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
1. **‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô** ‡πÄ‡∏ä‡πà‡∏ô "‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?"
2. **‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£** ‡πÄ‡∏ä‡πà‡∏ô "‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô ‡∏°‡∏µ‡∏Å‡∏≥‡πÑ‡∏£‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?"
3. **‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©** ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
4. **‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö** ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏á‡∏≤‡∏ô‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™ 1 ‡∏Å‡∏±‡∏ö 2"

### üîß ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô:
- **OCR ‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥** ‚Üí ‡πÄ‡∏û‡∏¥‡πà‡∏° Image Quality, ‡πÉ‡∏ä‡πâ Structure mode
- **‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** ‚Üí ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤ Knowledge Base ‡πÅ‡∏•‡πâ‡∏ß
- **‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** ‚Üí ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô, ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

---

## üöÄ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

### üìä Batch Processing:
- ‡πÄ‡∏õ‡∏¥‡∏î "Enable Batch Processing" ‡πÉ‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡πÅ‡∏£‡∏Å
- ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
- ‡πÉ‡∏ä‡πâ‡∏õ‡∏∏‡πà‡∏° "üß† Add All to Knowledge Base" ‡∏´‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à

### üîÑ Workflow ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
1. **‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å:** ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
2. **‡∏ó‡∏∏‡∏Å‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå:** ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà
3. **‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡∏à‡∏≥:** ‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
4. **‡∏ó‡∏∏‡∏Å‡πÄ‡∏î‡∏∑‡∏≠‡∏ô:** ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Knowledge Base

### üéõÔ∏è ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:
- **‡∏á‡∏≤‡∏ô OCR** ‚Üí Typhoon OCR 7B
- **‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‚Üí Typhoon2 8B  
- **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô** ‚Üí Qwen2.5 14B

---

## ‚ùì FAQ

**Q: ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏´‡∏≤‡∏¢‡πÑ‡∏´‡∏°‡∏ñ‡πâ‡∏≤‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå?**
A: ‡πÑ‡∏°‡πà‡∏´‡∏≤‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ SQLite ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö‡∏ñ‡∏≤‡∏ß‡∏£

**Q: ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏≠‡∏ü‡πÑ‡∏•‡∏ô‡πå‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°?**
A: ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô AI

**Q: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô?**
A: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡πâ‡∏á OCR ‡πÅ‡∏•‡∏∞ Q&A

**Q: ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?**
A: ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß 10MB, ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå

**Q: ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Knowledge Base ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°?**
A: ‡πÑ‡∏î‡πâ ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö Knowledge Base ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ‡∏õ‡∏∏‡πà‡∏°‡∏•‡∏ö‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
        """)

# Run the app
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"‚ùå Application Error: {str(e)}")
        st.error("Please refresh the page and try again.")
        st.error(f"Debug info: {traceback.format_exc()}")
